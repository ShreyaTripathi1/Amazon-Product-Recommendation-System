{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "166b9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9bebfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Swissmar Capstore Select Storage Rack for 18-...</td>\n",
       "      <td>Swissmar's capstore select 18 storage unit kee...</td>\n",
       "      <td>Home &amp; Kitchen Kitchen &amp; Dining Kitchen Utens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Gemini200 Delta CV-880 Gold Crown Livery Airc...</td>\n",
       "      <td>Welcome to the exciting world of GeminiJets! O...</td>\n",
       "      <td>Toys &amp; Games Hobbies Models &amp; Model Kits Pre-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Superior Threads 10501-2172 Magnifico Cream P...</td>\n",
       "      <td>For quilting and embroidery, this product is m...</td>\n",
       "      <td>Arts, Crafts &amp; Sewing Sewing Thread &amp; Floss S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Fashion Angels Color Rox Hair Chox Kit</td>\n",
       "      <td>Experiment with the haute trend of hair chalki...</td>\n",
       "      <td>Beauty &amp; Personal Care Hair Care Hair Colorin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Union Creative Giant Killing Figure 05: Daisu...</td>\n",
       "      <td>From Union Creative. Turn your display shelf i...</td>\n",
       "      <td>Toys &amp; Games › Action Figures &amp; Statues › Sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              Title  \\\n",
       "0   1   Swissmar Capstore Select Storage Rack for 18-...   \n",
       "1   2   Gemini200 Delta CV-880 Gold Crown Livery Airc...   \n",
       "2   5   Superior Threads 10501-2172 Magnifico Cream P...   \n",
       "3   6            Fashion Angels Color Rox Hair Chox Kit    \n",
       "4   8   Union Creative Giant Killing Figure 05: Daisu...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Swissmar's capstore select 18 storage unit kee...   \n",
       "1  Welcome to the exciting world of GeminiJets! O...   \n",
       "2  For quilting and embroidery, this product is m...   \n",
       "3  Experiment with the haute trend of hair chalki...   \n",
       "4  From Union Creative. Turn your display shelf i...   \n",
       "\n",
       "                                            Category  \n",
       "0   Home & Kitchen Kitchen & Dining Kitchen Utens...  \n",
       "1   Toys & Games Hobbies Models & Model Kits Pre-...  \n",
       "2   Arts, Crafts & Sewing Sewing Thread & Floss S...  \n",
       "3   Beauty & Personal Care Hair Care Hair Colorin...  \n",
       "4   Toys & Games › Action Figures & Statues › Sta...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"amazon_product.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3749f3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swissmar Capstore Select Storage Rack for 18-...</td>\n",
       "      <td>Swissmar's capstore select 18 storage unit kee...</td>\n",
       "      <td>Home &amp; Kitchen Kitchen &amp; Dining Kitchen Utens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gemini200 Delta CV-880 Gold Crown Livery Airc...</td>\n",
       "      <td>Welcome to the exciting world of GeminiJets! O...</td>\n",
       "      <td>Toys &amp; Games Hobbies Models &amp; Model Kits Pre-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Superior Threads 10501-2172 Magnifico Cream P...</td>\n",
       "      <td>For quilting and embroidery, this product is m...</td>\n",
       "      <td>Arts, Crafts &amp; Sewing Sewing Thread &amp; Floss S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fashion Angels Color Rox Hair Chox Kit</td>\n",
       "      <td>Experiment with the haute trend of hair chalki...</td>\n",
       "      <td>Beauty &amp; Personal Care Hair Care Hair Colorin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Union Creative Giant Killing Figure 05: Daisu...</td>\n",
       "      <td>From Union Creative. Turn your display shelf i...</td>\n",
       "      <td>Toys &amp; Games › Action Figures &amp; Statues › Sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0   Swissmar Capstore Select Storage Rack for 18-...   \n",
       "1   Gemini200 Delta CV-880 Gold Crown Livery Airc...   \n",
       "2   Superior Threads 10501-2172 Magnifico Cream P...   \n",
       "3            Fashion Angels Color Rox Hair Chox Kit    \n",
       "4   Union Creative Giant Killing Figure 05: Daisu...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Swissmar's capstore select 18 storage unit kee...   \n",
       "1  Welcome to the exciting world of GeminiJets! O...   \n",
       "2  For quilting and embroidery, this product is m...   \n",
       "3  Experiment with the haute trend of hair chalki...   \n",
       "4  From Union Creative. Turn your display shelf i...   \n",
       "\n",
       "                                            Category  \n",
       "0   Home & Kitchen Kitchen & Dining Kitchen Utens...  \n",
       "1   Toys & Games Hobbies Models & Model Kits Pre-...  \n",
       "2   Arts, Crafts & Sewing Sewing Thread & Floss S...  \n",
       "3   Beauty & Personal Care Hair Care Hair Colorin...  \n",
       "4   Toys & Games › Action Figures & Statues › Sta...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58b8daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is no null values, if any, delete it\n",
    "#lowercase title and description\n",
    "#tokenize words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf813221",
   "metadata": {},
   "source": [
    "Checking number of emplty cell in each coloumn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "765df9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title          0\n",
       "Description    0\n",
       "Category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756f010",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization is the process of breaking down a text into smaller units called tokens. These tokens can be words, phrases, symbols, or other meaningful elements. Tokenization is a fundamental step in natural language processing (NLP) as it helps in converting raw text into a format that can be more easily analyzed and processed.\n",
    "\n",
    "#### For example:\n",
    "###### 1. Word Tokenization:\n",
    "Splitting a sentence into individual words.\n",
    "\n",
    "Input: \"I love natural language processing.\"\n",
    "Tokens: [\"I\", \"love\", \"natural\", \"language\", \"processing\"]\n",
    "\n",
    "###### 2. Sentence Tokenization:\n",
    "Splitting a text into individual sentences.\n",
    "\n",
    "Input: \"Hello world. Welcome to NLP.\"\n",
    "Tokens: [\"Hello world.\", \"Welcome to NLP.\"]\n",
    "\n",
    "###### 3. Character Tokenization:\n",
    "Splitting a text into individual characters.\n",
    "\n",
    "Input: \"NLP\"\n",
    "Tokens: [\"N\", \"L\", \"P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3238ade7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenize',\n",
       " 'means',\n",
       " 'breaking',\n",
       " 'text',\n",
       " 'into',\n",
       " 'individual',\n",
       " 'units',\n",
       " ',',\n",
       " 'words',\n",
       " 'or',\n",
       " 'tokens']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize('Tokenize means breaking text into individual units, words or tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12df97bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sent Tokens.',\n",
       " 'This breaks whole content into individual sentences.',\n",
       " 'Simple!']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize('Sent Tokens. This breaks whole content into individual sentences. Simple!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af2b3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "def tonkenize_stem(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41b2f2",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its base or root form, typically by removing any suffixes or prefixes.\n",
    "This is a common technique in natural language processing (NLP) to simplify and standardize words, allowing for more effective text analysis and search. \n",
    "\n",
    "#### For example:\n",
    "The words \"running\", \"runner\", and \"ran\" can all be stemmed to the root word \"run\".  \n",
    "run={running, runner, ran}  \n",
    " \n",
    "\n",
    "In Python, stemming can be done using various libraries, with the most popular ones being the Natural Language Toolkit (nltk) and the SnowballStemmer from the nltk package, and the PorterStemmer.Here are some methods to perform stemming:  \n",
    "\n",
    "#### 1. Using NLTK's PorterStemmer\n",
    "    import nltk\n",
    "    from nltk.stem import PorterStemmer\n",
    "    porter_stemmer = PorterStemmer()   #Initialize the stemmer  \n",
    "    words = [\"running\", \"ran\", \"runner\", \"easily\", \"fairly\"]   #Example words  \n",
    "    stemmed_words = [porter_stemmer.stem(word) for word in words]   #Stem each word  \n",
    "    print(stemmed_words)\n",
    "\n",
    "    #Output: ['run', 'ran', 'runner', 'easili', 'fairli']  \n",
    "\n",
    "\n",
    "#### 2. Using NLTK's LancasterStemmer  \n",
    "    from nltk.stem import LancasterStemmer  \n",
    "    lancaster_stemmer = LancasterStemmer()   #Initialize the stemmer  \n",
    "    words = [\"running\", \"ran\", \"runner\", \"easily\", \"fairly\"]   #Example words  \n",
    "    stemmed_words = [lancaster_stemmer.stem(word) for word in words]   #Stem each word  \n",
    "    print(stemmed_words)\n",
    "\n",
    "    #Output: ['run', 'ran', 'run', 'easy', 'fair']  \n",
    "\n",
    "### 3. Using NLTK's SnowballStemmer  \n",
    "The Snowball Stemmer, or Porter2, is an improvement over the original Porter Stemmer and supports multiple languages.  \n",
    "\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    snowball_stemmer = SnowballStemmer(language='english')    #Initialize the stemmer  \n",
    "    words = [\"running\", \"ran\", \"runner\", \"easily\", \"fairly\"]    #Example words  \n",
    "    stemmed_words = [snowball_stemmer.stem(word) for word in words]   #Stem each word  \n",
    "    print(stemmed_words)\n",
    "\n",
    "    #Output: ['run', 'ran', 'runner', 'easili', 'fair']  \n",
    "\n",
    "#### 4. Using spaCy for Lemmatization (An Alternative to Stemming)  \n",
    "Although spaCy is more commonly used for lemmatization, which is a similar process to stemming but returns valid words, it's worth mentioning as an alternative.  \n",
    "Lemmatization is the process of reducing words to their base or dictionary form, known as a lemma. Unlike stemming, which often simply cuts off prefixes or suffixes, lemmatization considers the context and converts words to their meaningful base form. This process helps in improving the accuracy of text analysis by ensuring that different forms of a word are treated as the same base word.  \n",
    "\n",
    "Example of Lemmatization:  \n",
    "Words: \"running,\" \"ran,\" \"runner\"  \n",
    "Lemmas: \"run,\" \"run,\" \"runner\"  \n",
    "\n",
    "    import spacy  \n",
    "    nlp = spacy.load(\"en_core_web_sm\")    #Load spaCy's English language model  \n",
    "    words = [\"running\", \"ran\", \"runner\", \"easily\", \"fairly\"]    #Example words  \n",
    "    lemmas = [token.lemma_ for token in nlp(\" \".join(words))]    #Lemmatize each word  \n",
    "    print(lemmas)  \n",
    "\n",
    "    #Output: ['run', 'run', 'runner', 'easily', 'fairly']  \n",
    "\n",
    "\n",
    "\n",
    "In short  \n",
    "PorterStemmer: Widely used, less aggressive.  \n",
    "LancasterStemmer: More aggressive.  \n",
    "SnowballStemmer: Improved version of Porter Stemmer, supports multiple languages.  \n",
    "spaCy: Typically used for lemmatization, an alternative to stemming.  \n",
    "\n",
    "Each method has specific use cases, and the choice depends on the text processing task. We are currently using SnowballStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d61be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
